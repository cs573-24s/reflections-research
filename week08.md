https://dl.acm.org/doi/fullHtml/10.1145/3544548.3581323

The research paper I did mine on was called "On the Making of Alternative Data Encounters: The Odd Interpreters", and was about the exploration of IoT through the creation of multiple "Odd Interpreter" devices: seemingly purposeless IoT devices designed to reimagine our view of data. In truth, the paper lost me through a lot of the background material talking about the themes and sources behind their ideas, but the 'Odd Interpreters' themselves captivated me. I was especially interested in the Broadcast, a device that would monitor the transmissions of a particular smart speaker and then play a "sound" depending on the type of data - "locally stored" "sent to datacenter", "sent through undersea cable" ect. The experiment was designed to depict how data is physically transported across the world, and while this was interesting, I myself was more interested in the fact that more information was transmitted than they had thought. I suppose that says something about the way I percieve data, as merely data to be knowledgable and to protect, rather than to really understand it. Similarly the other two Odd Interpreters were about reimagining how to look at data in the home, with one measuring sunlight in an image put onto yellow cloth (Soft Fading), with another measuring accessing of smart plugs and creating a cookie recipe based on the inputs (Data Bakery) - I think these are both incredibly interesting ways of portraying data that I never thought of. The aim was to represent interacting with  in both a passive way and active way and I think that is a great way of 'engaging' with data, for the reason the writers suggested, that we don't properly engage with the data in our lives. Given the results of the experiment, I would propose slightly different functions of the Odd Interpreter. For the Broadcast, currently the sounds only play at a specific time: I think playing the sounds whenever they occur, and through speakers throughout the house, wuold give people a more accurate real-time depiction of what was happening to their data. For Soft Fading, I would make a way to record the fabric changing as it went, perhaps with a camera, so that it is something people could check casually - the testers describe being very worried about the outcome and having some understanding of what will appear could remove that worry and prompt more thinking as the experiment runs. Finally for the data bakery I think some more information would be helpful - the experimenters describe wondering why particular things were introduced to their recipes, and knowing more about what things cause what ingredients to be added/modified would help with increasing data understanding. In short, while I like the point of the study to make people think about what data is is good, I think the topic could be extended to knowing more about the data and gain a greater amount of info that I think would benefit people more.